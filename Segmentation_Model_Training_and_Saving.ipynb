{"cells":[{"cell_type":"markdown","metadata":{"id":"6tY8_t1q6EsI"},"source":["# **Check for GPU**"]},{"cell_type":"markdown","metadata":{"id":"kWByEPXVH-Nx"},"source":["Let's make sure that we have access to GPU. We are going to use nvidia-smi command to do that."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NoPAoImnGdHp","outputId":"e86a67f6-02c9-45ea-b5a6-ada8cd5d72e6","executionInfo":{"status":"ok","timestamp":1710594913978,"user_tz":-180,"elapsed":12,"user":{"displayName":"Elvis kiilu","userId":"18175971843584468454"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Sat Mar 16 13:15:11 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   49C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"kgQ_E-BQ6O4k"},"source":["# **Checking for current directory**"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PhPJT47UI48I","outputId":"6a82632b-09da-479b-ebaf-77db1318d5c9","executionInfo":{"status":"ok","timestamp":1710595052340,"user_tz":-180,"elapsed":7,"user":{"displayName":"Elvis kiilu","userId":"18175971843584468454"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}],"source":["import os\n","HOME = os.getcwd()\n","print(HOME)"]},{"cell_type":"markdown","metadata":{"id":"fLjR4f6EJHDs"},"source":["# YOLOv8 Installation"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NU1nr7ujJE01","outputId":"43233741-ccbd-456d-de87-63c6ee682bb1","executionInfo":{"status":"ok","timestamp":1710595359039,"user_tz":-180,"elapsed":299233,"user":{"displayName":"Elvis kiilu","userId":"18175971843584468454"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.1.29-py3-none-any.whl (721 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.3/721.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.1+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.17.1+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n","Collecting thop>=0.1.1 (from ultralytics)\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.49.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n","  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, thop, ultralytics\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 thop-0.1.1.post2209072238 ultralytics-8.1.29\n"]}],"source":["!pip install ultralytics"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vsprEmtwKESJ","outputId":"397314fa-be6b-4d3f-c33a-5ca188597bc4","executionInfo":{"status":"ok","timestamp":1710595366838,"user_tz":-180,"elapsed":7818,"user":{"displayName":"Elvis kiilu","userId":"18175971843584468454"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.1.29 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","Setup complete ✅ (2 CPUs, 12.7 GB RAM, 28.9/78.2 GB disk)\n"]}],"source":["from IPython import display\n","display.clear_output()\n","import ultralytics\n","ultralytics.checks()"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"qpjjC2MMKbDi","executionInfo":{"status":"ok","timestamp":1710595386877,"user_tz":-180,"elapsed":408,"user":{"displayName":"Elvis kiilu","userId":"18175971843584468454"}}},"outputs":[],"source":["from ultralytics import YOLO\n","from IPython.display import display,Image"]},{"cell_type":"markdown","source":["# **Unzipping Segmentation Weights**"],"metadata":{"id":"rWWGrws9UDuK"}},{"cell_type":"code","source":["!unzip /seg_weights.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iNJmi-pUE8VV","outputId":"4e8d0979-d859-469d-9ede-591cb2245386","executionInfo":{"status":"ok","timestamp":1710595610314,"user_tz":-180,"elapsed":656,"user":{"displayName":"Elvis kiilu","userId":"18175971843584468454"}}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  /seg_weights.zip\n","  inflating: content/runs/segment/train/weights/best.pt  \n"]}]},{"cell_type":"markdown","metadata":{"id":"6FTnfxOZKnVw"},"source":["# **Custom Model**"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"T_sGGErDNhJJ","executionInfo":{"status":"ok","timestamp":1710595661912,"user_tz":-180,"elapsed":421,"user":{"displayName":"Elvis kiilu","userId":"18175971843584468454"}}},"outputs":[],"source":["seg_model = \"content/runs/segment/train/weights/best.pt\""]},{"cell_type":"code","source":["model = YOLO(seg_model)\n","model.fuse()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JCVXppJUaMP9","outputId":"164375f0-3883-439f-f7c8-26efc427e8b1","executionInfo":{"status":"ok","timestamp":1710595892501,"user_tz":-180,"elapsed":1027,"user":{"displayName":"Elvis kiilu","userId":"18175971843584468454"}}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["YOLOv8s-seg summary (fused): 195 layers, 11785018 parameters, 0 gradients, 42.5 GFLOPs\n"]}]},{"cell_type":"code","source":["import torch\n","\n","# Dummy input (adjust according to your actual input shape)\n","dummy_input = torch.randn(1, 3, 576, 1024)\n","\n","# Export to ONNX\n","onnx_filename = \"yolov8s_seg_model.onnx\"\n","torch.onnx.export(model, dummy_input, onnx_filename, opset_version=12)\n","\n","print(\"Model exported to:\", onnx_filename)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"CHOS-3YMdexI","executionInfo":{"status":"error","timestamp":1710596668554,"user_tz":-180,"elapsed":107861,"user":{"displayName":"Elvis kiilu","userId":"18175971843584468454"}},"outputId":"517e7249-91d6-4d9c-c1f0-dedbf5029c78"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.1.29 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=content/runs/segment/train/weights/best.pt, data=coco8-seg.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=1024, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train2\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2801504  ultralytics.nn.modules.head.Segment          [80, 32, 128, [128, 256, 512]]\n","YOLOv8s-seg summary: 261 layers, 11821056 parameters, 11821040 gradients, 42.9 GFLOPs\n","\n","Transferred 87/417 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train2', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/coco8-seg/labels/train.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco8-seg/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to runs/segment/train2/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n","Image sizes 1024 train, 1024 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/segment/train2\u001b[0m\n","Starting training for 100 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      1/100      3.63G      2.427       4.91      6.386      3.011         13       1024: 100%|██████████| 1/1 [00:00<00:00,  3.47it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  6.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all          4         17          0          0          0          0          0          0          0          0\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      2/100      3.58G      3.164      5.162      6.646      3.453         13       1024: 100%|██████████| 1/1 [00:00<00:00,  3.77it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  5.85it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          4         17          0          0          0          0          0          0          0          0\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      3/100      3.64G      3.362      5.325      6.384      3.465         13       1024: 100%|██████████| 1/1 [00:00<00:00,  2.49it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.56it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          4         17          0          0          0          0          0          0          0          0\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      4/100      3.52G      3.095      5.686      6.648      3.361         13       1024: 100%|██████████| 1/1 [00:00<00:00,  3.60it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  8.97it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          4         17          0          0          0          0          0          0          0          0\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      5/100      3.53G      3.118      5.137      6.325       3.44         13       1024: 100%|██████████| 1/1 [00:00<00:00,  3.56it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  8.79it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          4         17          0          0          0          0          0          0          0          0\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      6/100      3.54G      2.786      4.576      6.594      3.039         13       1024: 100%|██████████| 1/1 [00:00<00:00,  3.60it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  8.52it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          4         17          0          0          0          0          0          0          0          0\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      7/100      3.54G      3.361      4.843      6.613      3.547         13       1024: 100%|██████████| 1/1 [00:00<00:00,  3.53it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  7.63it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          4         17          0          0          0          0          0          0          0          0\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      8/100      3.54G      2.854      4.322      6.417      3.168         13       1024: 100%|██████████| 1/1 [00:00<00:00,  2.70it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  7.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all          4         17          0          0          0          0          0          0          0          0\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      9/100      3.53G      3.069      4.559      6.348       3.29         13       1024: 100%|██████████| 1/1 [00:00<00:00,  3.24it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  8.52it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          4         17          0          0          0          0          0          0          0          0\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     10/100      3.54G      2.963      5.082      6.407      3.209         13       1024: 100%|██████████| 1/1 [00:00<00:00,  3.37it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.20it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          4         17          0          0          0          0          0          0          0          0\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     11/100      3.52G      3.217      4.462      6.557      3.472         13       1024: 100%|██████████| 1/1 [00:00<00:00,  3.49it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.39it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          4         17          0          0          0          0          0          0          0          0\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     12/100      3.53G      2.761      5.378      6.513      3.189         13       1024: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.40it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          4         17          0          0          0          0          0          0          0          0\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     13/100      3.53G      3.018      4.679      6.776       3.19         13       1024: 100%|██████████| 1/1 [00:00<00:00,  3.30it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  7.34it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          4         17          0          0          0          0          0          0          0          0\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     14/100      3.54G      2.495      4.809      6.164       2.93         13       1024: 100%|██████████| 1/1 [00:00<00:00,  3.59it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.03it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          4         17          0          0          0          0          0          0          0          0\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     15/100      3.54G      2.616      4.623      6.117      3.122         13       1024: 100%|██████████| 1/1 [00:00<00:00,  3.29it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  8.99it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          4         17          0          0          0          0          0          0          0          0\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     16/100      3.51G      3.305      4.612      6.445      3.488         13       1024: 100%|██████████| 1/1 [00:00<00:00,  2.84it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  7.84it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          4         17          0          0          0          0          0          0          0          0\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     17/100      3.53G      2.586      4.624      6.269      3.008         13       1024: 100%|██████████| 1/1 [00:00<00:00,  3.40it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.57it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          4         17          0          0          0          0          0          0          0          0\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     18/100      3.54G      3.446       4.34      6.704      3.641         13       1024: 100%|██████████| 1/1 [00:00<00:00,  3.84it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.31it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          4         17          0          0          0          0          0          0          0          0\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     19/100      3.54G      2.799      4.169      6.289      3.088         13       1024: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  5.91it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          4         17          0          0          0          0          0          0          0          0\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     20/100      3.51G      2.949      4.482      6.521      3.415         13       1024: 100%|██████████| 1/1 [00:00<00:00,  3.77it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.06it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          4         17          0          0          0          0          0          0          0          0\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     21/100      3.54G      2.872      4.695      6.583      2.987         13       1024: 100%|██████████| 1/1 [00:00<00:00,  3.30it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.56it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          4         17          0          0          0          0          0          0          0          0\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     22/100      3.51G      3.169      4.512      6.413       3.39         13       1024: 100%|██████████| 1/1 [00:00<00:00,  3.47it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.09it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          4         17          0          0          0          0          0          0          0          0\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     23/100      3.54G      2.499      4.475      6.119      2.986         13       1024: 100%|██████████| 1/1 [00:00<00:00,  3.21it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.22it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          4         17          0          0          0          0          0          0          0          0\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-866be8f90745>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Export to ONNX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0monnx_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"yolov8s_seg_model.onnx\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monnx_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopset_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model exported to:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monnx_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m    514\u001b[0m     \"\"\"\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m     _export(\n\u001b[0m\u001b[1;32m    517\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m   1588\u001b[0m             )\n\u001b[1;32m   1589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1590\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mexporter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1591\u001b[0m             val_keep_init_as_ip = _decide_keep_init_as_input(\n\u001b[1;32m   1592\u001b[0m                 \u001b[0mkeep_initializers_as_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36mexporter_context\u001b[0;34m(model, mode, verbose)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_beartype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeartype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexporter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_C_onnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainingMode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     with select_model_mode_for_export(\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmode_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable_apex_o2_state_dict_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36mselect_model_mode_for_export\u001b[0;34m(model, mode)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_C_onnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainingMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEVAL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;31m# else mode == _C_onnx.TrainingMode.PRESERVE, do nothing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m  \u001b[0;31m# attach optional HUB session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m         \u001b[0;31m# Update model and cfg after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    435\u001b[0m                 \u001b[0;31m# Save model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_model_save\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_fitness\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_period\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_period\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwdir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34mf\"epoch{self.epoch}.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/utils/patches.py\u001b[0m in \u001b[0;36mtorch_save\u001b[0;34m(use_dill, *args, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 3 retries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_torch_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# unable to save, possibly waiting for device to flush or antivirus scan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_disable_byteorder_record\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_end_of_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_stream\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"dXY0DzLjfm8A"},"source":["# **Object Tracking Implementation**"]},{"cell_type":"markdown","source":["# **With Speed Estimation and Counting**"],"metadata":{"id":"jeFq_Gt_chrG"}},{"cell_type":"code","source":["from collections import defaultdict\n","import cv2\n","import numpy as np\n","from ultralytics import YOLO\n","from ultralytics.solutions import distance_calculation\n","\n","# Load the YOLOv8 model\n","model = YOLO('content/runs/segment/train/weights/best.pt')\n","\n","# Open the video file\n","video_path = \"/traffic_-_27260 (540p).mp4\"\n","cap = cv2.VideoCapture(video_path)\n","\n","# Store the track history\n","track_history = defaultdict(lambda: [])\n","\n","# Get video properties\n","w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","fps = int(cap.get(cv2.CAP_PROP_FPS))\n","\n","# Define the output video file path with .mp4 extension\n","output_video_path = 'testoutput_video.mp4'\n","\n","# Define the codec and create a VideoWriter object for MP4\n","fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Use the MP4 codec\n","out = cv2.VideoWriter(output_video_path, fourcc, fps, (w, h))\n","\n","\n","# Initialize variables for object counting and speed estimation\n","last_frame_ids = set()\n","\"\"\"\n","# Assuming fps is the frame rate of the video\n","time_interval = 1 / fps  # Time interval between consecutive frames in seconds\n","\n","# Assuming pixel_to_meter is a conversion factor from pixels to meters\n","pixel_to_meter = 0.00026458333333719  # Since 1 Pixel = 0.00026458333333719 Meter\n","\n","# Assuming meter_to_km is a conversion factor from meters to kilometers\n","meter_to_km = 0.001  # 1 meter = 0.001 kilometer\n","\"\"\"\n","text_color = (78, 78, 78)\n","\n","# Loop through the video frames\n","while cap.isOpened():\n","    # Read a frame from the video\n","    success, frame = cap.read()\n","\n","    if success:\n","        # Run YOLOv8 tracking on the frame, persisting tracks between frames\n","        results = model.track(frame, persist=True, tracker=\"bytetrack.yaml\")\n","\n","        # Get the boxes and track IDs\n","        boxes = results[0].boxes.xywh.cpu()\n","        track_ids = results[0].boxes.id.int().cpu().tolist()\n","\n","        # Initialize counts and speeds\n","        object_count = len(boxes)\n","        speeds_km_per_h = []\n","\n","        # Visualize the results on the frame\n","        annotated_frame = results[0].plot()\n","\n","        # Plot the tracks and calculate speeds\n","        for box, track_id in zip(boxes, track_ids):\n","            x, y, w, h = box\n","            track = track_history[track_id]\n","            track.append((float(x), float(y)))  # x, y center point\n","            if len(track) > 1:  # Calculate speed when there are at least two points\n","                # Calculate displacement\n","                displacement = distance_calculation.DistanceCalculation()\n","\n","\n","\n","                # Calculate speed in km/s\n","                speed_km_per_s = displacement/ time_interval\n","\n","                # Convert speed from km/s to km/h\n","                speed_km_per_h = speed_km_per_s * 3600\n","\n","                # Display speed_km_per_h (km/h) for individual object\n","                cv2.putText(annotated_frame, f'Speed: {speed_km_per_h:.2f} km/h', (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, text_color, 2)\n","\n","\n","                # Draw the tracking lines\n","                points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))\n","                cv2.polylines(annotated_frame, [points], isClosed=False, color=(230, 0, 0), thickness=2)\n","\n","        # Display count on the annotated frame\n","        cv2.putText(annotated_frame, f'Count: {object_count}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n","\n","        # Update last frame IDs\n","        current_frame_ids = set(track_ids)\n","        new_objects = current_frame_ids - last_frame_ids\n","        lost_objects = last_frame_ids - current_frame_ids\n","        object_count += len(new_objects) - len(lost_objects)\n","\n","        # Write the annotated frame to the output video\n","        out.write(annotated_frame)\n","\n","        # Update last frame IDs\n","        last_frame_ids = current_frame_ids\n","\n","    else:\n","        # Break the loop if the end of the video is reached\n","        break\n","\n","# Release the video capture object and close the output video\n","cap.release()\n","out.release()\n","cv2.destroyAllWindows()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":558},"id":"zYJ_Occjcf_j","outputId":"7a358b14-121c-4713-a51e-0036494af650","executionInfo":{"status":"error","timestamp":1710596985028,"user_tz":-180,"elapsed":7083,"user":{"displayName":"Elvis kiilu","userId":"18175971843584468454"}}},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['lapx>=0.5.2'] not found, attempting AutoUpdate...\n","Collecting lapx>=0.5.2\n","  Downloading lapx-0.5.5-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 8.0 MB/s eta 0:00:00\n","Requirement already satisfied: Cython>=0.29.32 in /usr/local/lib/python3.10/dist-packages (from lapx>=0.5.2) (3.0.9)\n","Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from lapx>=0.5.2) (1.25.2)\n","Installing collected packages: lapx\n","Successfully installed lapx-0.5.5\n","\n","\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 6.2s, installed 1 package: ['lapx>=0.5.2']\n","\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n","\n","\n","0: 576x1024 4 cars, 32.8ms\n","Speed: 4.6ms preprocess, 32.8ms inference, 11.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 22.6ms\n","Speed: 4.0ms preprocess, 22.6ms inference, 7.1ms postprocess per image at shape (1, 3, 576, 1024)\n","WARNING ⚠️ Environment does not support cv2.imshow() or PIL Image.show()\n","\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'time_interval' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-7e4aed7a52c5>\u001b[0m in \u001b[0;36m<cell line: 45>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;31m# Calculate speed in km/s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mspeed_km_per_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisplacement\u001b[0m\u001b[0;34m/\u001b[0m \u001b[0mtime_interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0;31m# Convert speed from km/s to km/h\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'time_interval' is not defined"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JEQPF0EpvU2g","outputId":"b4fabd4a-1045-46dd-d894-185441add1ba","executionInfo":{"status":"ok","timestamp":1709644950853,"user_tz":-180,"elapsed":39323,"user":{"displayName":"Elvis kiilu","userId":"18175971843584468454"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["from collections import defaultdict\n","import cv2\n","import numpy as np\n","from ultralytics import YOLO\n","\n","# Load the YOLOv8 model\n","model = YOLO('content/runs/segment/train/weights/best.pt')\n","\n","# Open the video file\n","video_path = \"/traffic_-_27260 (540p).mp4\"\n","cap = cv2.VideoCapture(video_path)\n","\n","\n","# Store the track history\n","track_history = defaultdict(lambda: [])\n","\n","# Get video properties\n","w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","fps = int(cap.get(cv2.CAP_PROP_FPS))\n","\n","# Define the output video file path with .mp4 extension\n","output_video_path = 'deployedtestoutput_video.mp4'\n","\n","# Define the codec and create a VideoWriter object for MP4\n","fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Use the MP4 codec\n","out = cv2.VideoWriter(output_video_path, fourcc, fps, (w, h))\n","\n","\n","# Initialize variables for object counting and speed estimation\n","last_frame_ids = set()\n","\n","# Assuming fps is the frame rate of the video\n","time_interval = 1 / fps  # Time interval between consecutive frames in seconds\n","\n","\n","pixel_to_meter = 10 # Since 1 Pixel = 0.00026458333333719 Meter\n","\n","\n","meter_to_km = 0.001  # 1 meter = 0.001 kilometer\n","\n","text_color = (78, 78, 78)\n","\n","# Loop through the video frames\n","while cap.isOpened():\n","    # Read a frame from the video\n","    success, frame = cap.read()\n","\n","    if success:\n","        # Run YOLOv8 tracking on the frame, persisting tracks between frames\n","        results = model.track(frame, persist=True, tracker=\"bytetrack.yaml\")\n","\n","        # Get the boxes and track IDs\n","        boxes = results[0].boxes.xywh.cpu()\n","        track_ids = results[0].boxes.id.int().cpu().tolist()\n","\n","        # Initialize counts and speeds\n","        object_count = len(boxes)\n","        speeds_km_per_h = []\n","\n","        # Visualize the results on the frame\n","        annotated_frame = results[0].plot()\n","\n","        # Plot the tracks and calculate speeds\n","        for box, track_id in zip(boxes, track_ids):\n","            x, y, w, h = box\n","            track = track_history[track_id]\n","            track.append((float(x), float(y)))  # x, y center point\n","            if len(track) > 1:  # Calculate speed when there are at least two points\n","                # Calculate displacement\n","                displacement = np.linalg.norm(np.array(track[-1]) - np.array(track[-2]))\n","\n","                # Convert displacement from pixels to kilometers\n","                displacement_km = displacement * pixel_to_meter * meter_to_km\n","\n","                # Calculate speed in km/s\n","                speed_km_per_s = displacement_km / time_interval\n","\n","                # Convert speed from km/s to km/h\n","                speed_km_per_h = speed_km_per_s * 3600\n","\n","                # Display speed_km_per_h (km/h) for individual object\n","                cv2.putText(annotated_frame, f'Speed: {speed_km_per_h:.2f} km/h', (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, text_color, 2)\n","\n","\n","                # Draw the tracking lines\n","                points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))\n","                cv2.polylines(annotated_frame, [points], isClosed=False, color=(230, 0, 0), thickness=2)\n","\n","        # Display count on the annotated frame\n","        cv2.putText(annotated_frame, f'Count: {object_count}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n","\n","        # Update last frame IDs\n","        current_frame_ids = set(track_ids)\n","        new_objects = current_frame_ids - last_frame_ids\n","        lost_objects = last_frame_ids - current_frame_ids\n","        object_count += len(new_objects) - len(lost_objects)\n","\n","        # Write the annotated frame to the output video\n","        out.write(annotated_frame)\n","\n","        # Update last frame IDs\n","        last_frame_ids = current_frame_ids\n","\n","    else:\n","        # Break the loop if the end of the video is reached\n","        break\n","\n","# Release the video capture object and close the output video\n","cap.release()\n","out.release()\n","cv2.destroyAllWindows()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l4EzA8jHkUVa","outputId":"faee9213-854d-4682-b8be-55125c065da0","executionInfo":{"status":"ok","timestamp":1710597502796,"user_tz":-180,"elapsed":19795,"user":{"displayName":"Elvis kiilu","userId":"18175971843584468454"}}},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","0: 576x1024 4 cars, 29.8ms\n","Speed: 4.3ms preprocess, 29.8ms inference, 9.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 24.1ms\n","Speed: 5.1ms preprocess, 24.1ms inference, 6.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 21.0ms\n","Speed: 3.4ms preprocess, 21.0ms inference, 6.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 21.0ms\n","Speed: 5.0ms preprocess, 21.0ms inference, 5.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 21.0ms\n","Speed: 4.5ms preprocess, 21.0ms inference, 5.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 17.7ms\n","Speed: 4.6ms preprocess, 17.7ms inference, 5.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 17.7ms\n","Speed: 5.2ms preprocess, 17.7ms inference, 6.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 17.4ms\n","Speed: 5.3ms preprocess, 17.4ms inference, 5.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 17.5ms\n","Speed: 4.0ms preprocess, 17.5ms inference, 5.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 17.4ms\n","Speed: 5.1ms preprocess, 17.4ms inference, 5.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 17.4ms\n","Speed: 4.8ms preprocess, 17.4ms inference, 5.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 17.5ms\n","Speed: 4.7ms preprocess, 17.5ms inference, 5.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 16.2ms\n","Speed: 4.2ms preprocess, 16.2ms inference, 6.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 16.0ms\n","Speed: 4.4ms preprocess, 16.0ms inference, 5.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 15.8ms\n","Speed: 5.1ms preprocess, 15.8ms inference, 6.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 15.8ms\n","Speed: 4.6ms preprocess, 15.8ms inference, 5.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.9ms\n","Speed: 3.9ms preprocess, 14.9ms inference, 6.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.9ms\n","Speed: 4.7ms preprocess, 14.9ms inference, 5.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.9ms\n","Speed: 4.4ms preprocess, 14.9ms inference, 5.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.8ms\n","Speed: 4.4ms preprocess, 14.8ms inference, 6.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.6ms\n","Speed: 4.2ms preprocess, 14.6ms inference, 6.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.7ms\n","Speed: 5.2ms preprocess, 14.7ms inference, 6.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.6ms\n","Speed: 4.8ms preprocess, 14.6ms inference, 6.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.6ms\n","Speed: 5.6ms preprocess, 14.6ms inference, 6.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 18.4ms\n","Speed: 5.4ms preprocess, 18.4ms inference, 7.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.3ms\n","Speed: 4.4ms preprocess, 14.3ms inference, 7.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.5ms\n","Speed: 5.2ms preprocess, 14.5ms inference, 7.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.2ms\n","Speed: 5.1ms preprocess, 14.2ms inference, 7.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.2ms\n","Speed: 5.1ms preprocess, 14.2ms inference, 7.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.2ms\n","Speed: 4.5ms preprocess, 14.2ms inference, 7.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.3ms\n","Speed: 4.9ms preprocess, 14.3ms inference, 8.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 16.2ms\n","Speed: 5.0ms preprocess, 16.2ms inference, 7.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 16.5ms\n","Speed: 5.1ms preprocess, 16.5ms inference, 7.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.2ms\n","Speed: 4.5ms preprocess, 14.2ms inference, 7.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.3ms\n","Speed: 4.7ms preprocess, 14.3ms inference, 7.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 13.8ms\n","Speed: 5.4ms preprocess, 13.8ms inference, 7.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.2ms\n","Speed: 5.7ms preprocess, 14.2ms inference, 7.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 13.9ms\n","Speed: 4.7ms preprocess, 13.9ms inference, 7.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 13.9ms\n","Speed: 4.6ms preprocess, 13.9ms inference, 8.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 13.9ms\n","Speed: 4.8ms preprocess, 13.9ms inference, 7.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 13.8ms\n","Speed: 3.6ms preprocess, 13.8ms inference, 7.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 13.9ms\n","Speed: 4.7ms preprocess, 13.9ms inference, 8.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 13.9ms\n","Speed: 5.3ms preprocess, 13.9ms inference, 7.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 13.8ms\n","Speed: 6.5ms preprocess, 13.8ms inference, 7.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 13.8ms\n","Speed: 4.0ms preprocess, 13.8ms inference, 7.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 13.9ms\n","Speed: 4.3ms preprocess, 13.9ms inference, 7.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 13.8ms\n","Speed: 4.7ms preprocess, 13.8ms inference, 7.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 13.8ms\n","Speed: 4.5ms preprocess, 13.8ms inference, 6.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 13.9ms\n","Speed: 5.3ms preprocess, 13.9ms inference, 6.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 13.8ms\n","Speed: 4.7ms preprocess, 13.8ms inference, 6.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 16.0ms\n","Speed: 4.2ms preprocess, 16.0ms inference, 7.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 19.6ms\n","Speed: 5.4ms preprocess, 19.6ms inference, 9.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 20.6ms\n","Speed: 5.4ms preprocess, 20.6ms inference, 8.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 18.9ms\n","Speed: 4.8ms preprocess, 18.9ms inference, 6.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 22.2ms\n","Speed: 7.3ms preprocess, 22.2ms inference, 9.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 16.0ms\n","Speed: 4.8ms preprocess, 16.0ms inference, 9.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 16.8ms\n","Speed: 4.6ms preprocess, 16.8ms inference, 7.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 16.4ms\n","Speed: 4.7ms preprocess, 16.4ms inference, 7.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.6ms\n","Speed: 5.0ms preprocess, 14.6ms inference, 8.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 17.0ms\n","Speed: 4.8ms preprocess, 17.0ms inference, 8.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 17.2ms\n","Speed: 4.7ms preprocess, 17.2ms inference, 7.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.4ms\n","Speed: 4.7ms preprocess, 14.4ms inference, 6.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.8ms\n","Speed: 6.9ms preprocess, 14.8ms inference, 7.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 16.1ms\n","Speed: 4.9ms preprocess, 16.1ms inference, 6.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.8ms\n","Speed: 4.7ms preprocess, 14.8ms inference, 7.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.8ms\n","Speed: 4.9ms preprocess, 14.8ms inference, 7.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.7ms\n","Speed: 5.0ms preprocess, 14.7ms inference, 7.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 17.9ms\n","Speed: 5.3ms preprocess, 17.9ms inference, 7.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.5ms\n","Speed: 4.8ms preprocess, 14.5ms inference, 7.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 15.1ms\n","Speed: 4.7ms preprocess, 15.1ms inference, 7.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 3 cars, 15.8ms\n","Speed: 5.8ms preprocess, 15.8ms inference, 7.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 3 cars, 20.2ms\n","Speed: 8.3ms preprocess, 20.2ms inference, 6.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 3 cars, 20.1ms\n","Speed: 6.8ms preprocess, 20.1ms inference, 7.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 3 cars, 19.5ms\n","Speed: 4.8ms preprocess, 19.5ms inference, 6.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 3 cars, 15.9ms\n","Speed: 4.8ms preprocess, 15.9ms inference, 6.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 3 cars, 28.7ms\n","Speed: 6.1ms preprocess, 28.7ms inference, 7.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 19.0ms\n","Speed: 4.7ms preprocess, 19.0ms inference, 6.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 15.9ms\n","Speed: 4.8ms preprocess, 15.9ms inference, 7.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 18.6ms\n","Speed: 5.0ms preprocess, 18.6ms inference, 7.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 20.2ms\n","Speed: 5.1ms preprocess, 20.2ms inference, 7.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 23.2ms\n","Speed: 6.1ms preprocess, 23.2ms inference, 7.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 22.0ms\n","Speed: 6.0ms preprocess, 22.0ms inference, 7.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 16.1ms\n","Speed: 4.3ms preprocess, 16.1ms inference, 5.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 16.2ms\n","Speed: 6.2ms preprocess, 16.2ms inference, 6.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 15.9ms\n","Speed: 4.1ms preprocess, 15.9ms inference, 6.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 15.9ms\n","Speed: 4.7ms preprocess, 15.9ms inference, 7.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 15.8ms\n","Speed: 5.0ms preprocess, 15.8ms inference, 7.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 15.9ms\n","Speed: 4.8ms preprocess, 15.9ms inference, 7.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 15.6ms\n","Speed: 4.3ms preprocess, 15.6ms inference, 8.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 15.6ms\n","Speed: 4.5ms preprocess, 15.6ms inference, 7.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 15.6ms\n","Speed: 4.7ms preprocess, 15.6ms inference, 7.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 19.8ms\n","Speed: 4.6ms preprocess, 19.8ms inference, 9.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 15.6ms\n","Speed: 4.5ms preprocess, 15.6ms inference, 7.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 14.5ms\n","Speed: 4.3ms preprocess, 14.5ms inference, 6.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 14.4ms\n","Speed: 5.0ms preprocess, 14.4ms inference, 6.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 14.3ms\n","Speed: 5.1ms preprocess, 14.3ms inference, 6.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 14.4ms\n","Speed: 4.0ms preprocess, 14.4ms inference, 6.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 14.5ms\n","Speed: 4.5ms preprocess, 14.5ms inference, 6.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 14.3ms\n","Speed: 4.6ms preprocess, 14.3ms inference, 6.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 14.4ms\n","Speed: 4.4ms preprocess, 14.4ms inference, 6.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 14.4ms\n","Speed: 5.3ms preprocess, 14.4ms inference, 5.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 14.4ms\n","Speed: 4.5ms preprocess, 14.4ms inference, 6.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 14.4ms\n","Speed: 4.3ms preprocess, 14.4ms inference, 6.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 14.3ms\n","Speed: 4.5ms preprocess, 14.3ms inference, 6.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 14.4ms\n","Speed: 4.3ms preprocess, 14.4ms inference, 6.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 14.4ms\n","Speed: 4.2ms preprocess, 14.4ms inference, 6.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 14.4ms\n","Speed: 4.3ms preprocess, 14.4ms inference, 6.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 14.4ms\n","Speed: 4.1ms preprocess, 14.4ms inference, 6.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.1ms\n","Speed: 4.0ms preprocess, 14.1ms inference, 5.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.2ms\n","Speed: 4.4ms preprocess, 14.2ms inference, 5.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.1ms\n","Speed: 4.5ms preprocess, 14.1ms inference, 6.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.1ms\n","Speed: 4.9ms preprocess, 14.1ms inference, 5.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.1ms\n","Speed: 4.8ms preprocess, 14.1ms inference, 6.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.1ms\n","Speed: 3.4ms preprocess, 14.1ms inference, 6.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.1ms\n","Speed: 4.9ms preprocess, 14.1ms inference, 6.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.2ms\n","Speed: 4.5ms preprocess, 14.2ms inference, 7.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.5ms\n","Speed: 6.5ms preprocess, 14.5ms inference, 6.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.2ms\n","Speed: 4.4ms preprocess, 14.2ms inference, 6.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.1ms\n","Speed: 4.6ms preprocess, 14.1ms inference, 6.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.1ms\n","Speed: 4.1ms preprocess, 14.1ms inference, 6.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.4ms\n","Speed: 4.6ms preprocess, 14.4ms inference, 6.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 16.8ms\n","Speed: 4.6ms preprocess, 16.8ms inference, 6.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.1ms\n","Speed: 4.6ms preprocess, 14.1ms inference, 6.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.1ms\n","Speed: 4.8ms preprocess, 14.1ms inference, 6.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.1ms\n","Speed: 4.4ms preprocess, 14.1ms inference, 6.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.1ms\n","Speed: 4.7ms preprocess, 14.1ms inference, 6.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 16.4ms\n","Speed: 5.2ms preprocess, 16.4ms inference, 7.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.1ms\n","Speed: 4.3ms preprocess, 14.1ms inference, 6.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.1ms\n","Speed: 4.8ms preprocess, 14.1ms inference, 7.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.2ms\n","Speed: 5.2ms preprocess, 14.2ms inference, 7.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 19.0ms\n","Speed: 5.1ms preprocess, 19.0ms inference, 6.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.2ms\n","Speed: 4.8ms preprocess, 14.2ms inference, 7.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.1ms\n","Speed: 4.8ms preprocess, 14.1ms inference, 7.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.1ms\n","Speed: 4.5ms preprocess, 14.1ms inference, 8.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.2ms\n","Speed: 4.6ms preprocess, 14.2ms inference, 7.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 13.9ms\n","Speed: 5.4ms preprocess, 13.9ms inference, 7.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 14.1ms\n","Speed: 4.4ms preprocess, 14.1ms inference, 7.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 13.9ms\n","Speed: 4.4ms preprocess, 13.9ms inference, 7.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 13.9ms\n","Speed: 4.7ms preprocess, 13.9ms inference, 7.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.0ms\n","Speed: 4.4ms preprocess, 14.0ms inference, 8.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 13.9ms\n","Speed: 4.9ms preprocess, 13.9ms inference, 7.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 13.8ms\n","Speed: 4.4ms preprocess, 13.8ms inference, 7.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.0ms\n","Speed: 4.6ms preprocess, 14.0ms inference, 7.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 13.9ms\n","Speed: 4.7ms preprocess, 13.9ms inference, 7.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 14.1ms\n","Speed: 5.1ms preprocess, 14.1ms inference, 6.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 13.9ms\n","Speed: 4.6ms preprocess, 13.9ms inference, 6.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 14.0ms\n","Speed: 5.0ms preprocess, 14.0ms inference, 6.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 14.0ms\n","Speed: 5.1ms preprocess, 14.0ms inference, 8.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 15.4ms\n","Speed: 4.8ms preprocess, 15.4ms inference, 6.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 17.5ms\n","Speed: 3.9ms preprocess, 17.5ms inference, 7.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 14.0ms\n","Speed: 4.7ms preprocess, 14.0ms inference, 6.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 3 cars, 13.9ms\n","Speed: 4.4ms preprocess, 13.9ms inference, 5.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 3 cars, 14.1ms\n","Speed: 4.4ms preprocess, 14.1ms inference, 6.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 3 cars, 14.0ms\n","Speed: 3.4ms preprocess, 14.0ms inference, 6.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 3 cars, 14.0ms\n","Speed: 4.6ms preprocess, 14.0ms inference, 6.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 3 cars, 14.0ms\n","Speed: 4.6ms preprocess, 14.0ms inference, 6.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 14.1ms\n","Speed: 5.0ms preprocess, 14.1ms inference, 5.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 13.9ms\n","Speed: 4.5ms preprocess, 13.9ms inference, 5.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 14.0ms\n","Speed: 4.7ms preprocess, 14.0ms inference, 5.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 13.9ms\n","Speed: 4.3ms preprocess, 13.9ms inference, 5.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 13.9ms\n","Speed: 4.9ms preprocess, 13.9ms inference, 5.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 14.0ms\n","Speed: 4.9ms preprocess, 14.0ms inference, 5.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 14.0ms\n","Speed: 4.7ms preprocess, 14.0ms inference, 5.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 14.0ms\n","Speed: 4.6ms preprocess, 14.0ms inference, 5.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 14.1ms\n","Speed: 4.7ms preprocess, 14.1ms inference, 5.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 13.9ms\n","Speed: 4.6ms preprocess, 13.9ms inference, 4.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 14.0ms\n","Speed: 5.2ms preprocess, 14.0ms inference, 5.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 14.0ms\n","Speed: 5.1ms preprocess, 14.0ms inference, 5.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 14.1ms\n","Speed: 4.7ms preprocess, 14.1ms inference, 6.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 15.6ms\n","Speed: 5.1ms preprocess, 15.6ms inference, 7.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 14.6ms\n","Speed: 5.3ms preprocess, 14.6ms inference, 6.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 14.0ms\n","Speed: 5.1ms preprocess, 14.0ms inference, 7.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 13.9ms\n","Speed: 4.6ms preprocess, 13.9ms inference, 6.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.1ms\n","Speed: 4.6ms preprocess, 14.1ms inference, 7.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 13.9ms\n","Speed: 4.9ms preprocess, 13.9ms inference, 7.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.2ms\n","Speed: 4.5ms preprocess, 14.2ms inference, 6.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.0ms\n","Speed: 4.7ms preprocess, 14.0ms inference, 6.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 15.1ms\n","Speed: 5.4ms preprocess, 15.1ms inference, 7.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.5ms\n","Speed: 4.9ms preprocess, 14.5ms inference, 7.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 14.3ms\n","Speed: 5.3ms preprocess, 14.3ms inference, 7.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 15.1ms\n","Speed: 5.0ms preprocess, 15.1ms inference, 7.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 14.1ms\n","Speed: 5.2ms preprocess, 14.1ms inference, 7.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 14.0ms\n","Speed: 5.0ms preprocess, 14.0ms inference, 7.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 14.0ms\n","Speed: 5.6ms preprocess, 14.0ms inference, 7.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 14.0ms\n","Speed: 5.6ms preprocess, 14.0ms inference, 7.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 14.4ms\n","Speed: 5.9ms preprocess, 14.4ms inference, 7.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 14.0ms\n","Speed: 5.7ms preprocess, 14.0ms inference, 8.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 14.0ms\n","Speed: 4.5ms preprocess, 14.0ms inference, 7.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 18.2ms\n","Speed: 4.9ms preprocess, 18.2ms inference, 7.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 13.9ms\n","Speed: 4.9ms preprocess, 13.9ms inference, 7.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 14.0ms\n","Speed: 4.7ms preprocess, 14.0ms inference, 7.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 14.1ms\n","Speed: 5.3ms preprocess, 14.1ms inference, 8.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 14.0ms\n","Speed: 4.1ms preprocess, 14.0ms inference, 7.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 15.2ms\n","Speed: 5.0ms preprocess, 15.2ms inference, 7.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 13.9ms\n","Speed: 4.5ms preprocess, 13.9ms inference, 7.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 13.9ms\n","Speed: 4.8ms preprocess, 13.9ms inference, 6.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 14.0ms\n","Speed: 3.7ms preprocess, 14.0ms inference, 6.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 13.9ms\n","Speed: 4.0ms preprocess, 13.9ms inference, 6.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 13.9ms\n","Speed: 3.2ms preprocess, 13.9ms inference, 7.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 13.9ms\n","Speed: 4.7ms preprocess, 13.9ms inference, 6.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 14.0ms\n","Speed: 4.9ms preprocess, 14.0ms inference, 8.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 13.8ms\n","Speed: 4.7ms preprocess, 13.8ms inference, 7.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 14.0ms\n","Speed: 4.9ms preprocess, 14.0ms inference, 7.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 13.9ms\n","Speed: 5.0ms preprocess, 13.9ms inference, 7.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 14.6ms\n","Speed: 5.2ms preprocess, 14.6ms inference, 7.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 13.8ms\n","Speed: 3.6ms preprocess, 13.8ms inference, 7.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 14.3ms\n","Speed: 6.4ms preprocess, 14.3ms inference, 8.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 13.9ms\n","Speed: 5.2ms preprocess, 13.9ms inference, 8.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 14.0ms\n","Speed: 5.8ms preprocess, 14.0ms inference, 7.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 13.8ms\n","Speed: 4.9ms preprocess, 13.8ms inference, 7.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 13.9ms\n","Speed: 5.0ms preprocess, 13.9ms inference, 7.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 13.9ms\n","Speed: 5.2ms preprocess, 13.9ms inference, 7.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 13.9ms\n","Speed: 5.3ms preprocess, 13.9ms inference, 7.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 13.9ms\n","Speed: 4.9ms preprocess, 13.9ms inference, 7.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 13.9ms\n","Speed: 4.2ms preprocess, 13.9ms inference, 7.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 13.9ms\n","Speed: 4.8ms preprocess, 13.9ms inference, 7.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 13.9ms\n","Speed: 3.6ms preprocess, 13.9ms inference, 7.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 13.9ms\n","Speed: 4.5ms preprocess, 13.9ms inference, 7.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 15.1ms\n","Speed: 5.0ms preprocess, 15.1ms inference, 7.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 14.0ms\n","Speed: 4.7ms preprocess, 14.0ms inference, 8.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 14.0ms\n","Speed: 4.9ms preprocess, 14.0ms inference, 7.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 14.0ms\n","Speed: 4.5ms preprocess, 14.0ms inference, 7.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 13.9ms\n","Speed: 5.1ms preprocess, 13.9ms inference, 7.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 14.0ms\n","Speed: 3.4ms preprocess, 14.0ms inference, 7.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 13.7ms\n","Speed: 4.5ms preprocess, 13.7ms inference, 7.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 13.9ms\n","Speed: 4.7ms preprocess, 13.9ms inference, 7.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 13.9ms\n","Speed: 4.8ms preprocess, 13.9ms inference, 7.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 14.6ms\n","Speed: 5.0ms preprocess, 14.6ms inference, 7.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 13.9ms\n","Speed: 5.1ms preprocess, 13.9ms inference, 7.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 13.7ms\n","Speed: 4.1ms preprocess, 13.7ms inference, 7.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 14.8ms\n","Speed: 4.2ms preprocess, 14.8ms inference, 7.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 13.9ms\n","Speed: 4.2ms preprocess, 13.9ms inference, 7.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 14.0ms\n","Speed: 4.9ms preprocess, 14.0ms inference, 7.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 13.7ms\n","Speed: 4.8ms preprocess, 13.7ms inference, 7.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 13.9ms\n","Speed: 4.2ms preprocess, 13.9ms inference, 7.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 13.9ms\n","Speed: 4.9ms preprocess, 13.9ms inference, 7.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 13.7ms\n","Speed: 6.4ms preprocess, 13.7ms inference, 7.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 13.8ms\n","Speed: 4.5ms preprocess, 13.8ms inference, 7.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 13.9ms\n","Speed: 5.0ms preprocess, 13.9ms inference, 7.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 13.8ms\n","Speed: 5.4ms preprocess, 13.8ms inference, 7.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 13.7ms\n","Speed: 5.0ms preprocess, 13.7ms inference, 7.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 13.6ms\n","Speed: 5.9ms preprocess, 13.6ms inference, 8.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 13.8ms\n","Speed: 7.0ms preprocess, 13.8ms inference, 8.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 9 cars, 17.8ms\n","Speed: 5.6ms preprocess, 17.8ms inference, 7.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 9 cars, 13.8ms\n","Speed: 5.3ms preprocess, 13.8ms inference, 7.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 9 cars, 13.8ms\n","Speed: 4.8ms preprocess, 13.8ms inference, 7.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 9 cars, 13.7ms\n","Speed: 3.5ms preprocess, 13.7ms inference, 8.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 13.9ms\n","Speed: 5.5ms preprocess, 13.9ms inference, 6.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 9 cars, 13.8ms\n","Speed: 5.6ms preprocess, 13.8ms inference, 6.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 9 cars, 13.9ms\n","Speed: 5.8ms preprocess, 13.9ms inference, 7.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 9 cars, 13.8ms\n","Speed: 5.0ms preprocess, 13.8ms inference, 7.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 9 cars, 13.9ms\n","Speed: 4.9ms preprocess, 13.9ms inference, 9.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 9 cars, 13.9ms\n","Speed: 4.7ms preprocess, 13.9ms inference, 7.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 13.9ms\n","Speed: 4.6ms preprocess, 13.9ms inference, 7.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 13.9ms\n","Speed: 4.9ms preprocess, 13.9ms inference, 6.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 13.8ms\n","Speed: 4.6ms preprocess, 13.8ms inference, 6.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 14.0ms\n","Speed: 5.1ms preprocess, 14.0ms inference, 6.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 14.0ms\n","Speed: 4.8ms preprocess, 14.0ms inference, 6.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 14.0ms\n","Speed: 4.6ms preprocess, 14.0ms inference, 5.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 14.1ms\n","Speed: 4.1ms preprocess, 14.1ms inference, 7.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 14.0ms\n","Speed: 4.6ms preprocess, 14.0ms inference, 7.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 20.2ms\n","Speed: 5.7ms preprocess, 20.2ms inference, 9.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 14.0ms\n","Speed: 4.8ms preprocess, 14.0ms inference, 7.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 14.0ms\n","Speed: 5.6ms preprocess, 14.0ms inference, 7.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 14.1ms\n","Speed: 4.8ms preprocess, 14.1ms inference, 6.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 14.1ms\n","Speed: 4.3ms preprocess, 14.1ms inference, 8.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 18.0ms\n","Speed: 5.0ms preprocess, 18.0ms inference, 6.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 19.6ms\n","Speed: 4.9ms preprocess, 19.6ms inference, 7.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 18.9ms\n","Speed: 5.2ms preprocess, 18.9ms inference, 7.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 15.8ms\n","Speed: 4.7ms preprocess, 15.8ms inference, 7.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 17.8ms\n","Speed: 5.0ms preprocess, 17.8ms inference, 6.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 18.9ms\n","Speed: 5.3ms preprocess, 18.9ms inference, 6.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 19.6ms\n","Speed: 5.0ms preprocess, 19.6ms inference, 7.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 16.8ms\n","Speed: 5.9ms preprocess, 16.8ms inference, 7.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 17.6ms\n","Speed: 4.9ms preprocess, 17.6ms inference, 6.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 15.2ms\n","Speed: 5.5ms preprocess, 15.2ms inference, 7.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 14.9ms\n","Speed: 5.6ms preprocess, 14.9ms inference, 8.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 18.0ms\n","Speed: 4.8ms preprocess, 18.0ms inference, 9.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 20.1ms\n","Speed: 4.7ms preprocess, 20.1ms inference, 6.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 14.5ms\n","Speed: 4.5ms preprocess, 14.5ms inference, 7.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 14.3ms\n","Speed: 4.7ms preprocess, 14.3ms inference, 7.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 15.3ms\n","Speed: 4.7ms preprocess, 15.3ms inference, 7.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 14.5ms\n","Speed: 5.8ms preprocess, 14.5ms inference, 8.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 14.2ms\n","Speed: 4.6ms preprocess, 14.2ms inference, 7.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 15.8ms\n","Speed: 6.8ms preprocess, 15.8ms inference, 7.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 17.3ms\n","Speed: 7.1ms preprocess, 17.3ms inference, 7.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 21.7ms\n","Speed: 10.5ms preprocess, 21.7ms inference, 7.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 19.4ms\n","Speed: 7.6ms preprocess, 19.4ms inference, 7.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 21.7ms\n","Speed: 5.9ms preprocess, 21.7ms inference, 8.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 16.5ms\n","Speed: 5.2ms preprocess, 16.5ms inference, 8.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 20.1ms\n","Speed: 5.0ms preprocess, 20.1ms inference, 9.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 19.9ms\n","Speed: 4.7ms preprocess, 19.9ms inference, 9.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 22.8ms\n","Speed: 5.7ms preprocess, 22.8ms inference, 7.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 20.2ms\n","Speed: 4.9ms preprocess, 20.2ms inference, 7.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 22.9ms\n","Speed: 4.9ms preprocess, 22.9ms inference, 7.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 21.4ms\n","Speed: 5.4ms preprocess, 21.4ms inference, 7.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 21.0ms\n","Speed: 4.9ms preprocess, 21.0ms inference, 7.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 17.2ms\n","Speed: 5.0ms preprocess, 17.2ms inference, 6.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 17.2ms\n","Speed: 5.5ms preprocess, 17.2ms inference, 5.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 16.9ms\n","Speed: 4.7ms preprocess, 16.9ms inference, 5.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 17.4ms\n","Speed: 5.2ms preprocess, 17.4ms inference, 6.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 16.4ms\n","Speed: 5.4ms preprocess, 16.4ms inference, 5.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 16.2ms\n","Speed: 4.8ms preprocess, 16.2ms inference, 5.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 16.2ms\n","Speed: 5.0ms preprocess, 16.2ms inference, 5.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 16.2ms\n","Speed: 5.5ms preprocess, 16.2ms inference, 5.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 16.1ms\n","Speed: 5.0ms preprocess, 16.1ms inference, 5.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 16.2ms\n","Speed: 3.7ms preprocess, 16.2ms inference, 5.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 16.2ms\n","Speed: 4.1ms preprocess, 16.2ms inference, 5.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 21.2ms\n","Speed: 5.1ms preprocess, 21.2ms inference, 7.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 15.2ms\n","Speed: 5.6ms preprocess, 15.2ms inference, 6.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 15.2ms\n","Speed: 5.7ms preprocess, 15.2ms inference, 6.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 15.1ms\n","Speed: 4.9ms preprocess, 15.1ms inference, 6.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 15.1ms\n","Speed: 4.5ms preprocess, 15.1ms inference, 5.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 15.1ms\n","Speed: 3.6ms preprocess, 15.1ms inference, 5.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 15.2ms\n","Speed: 4.7ms preprocess, 15.2ms inference, 5.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 14.9ms\n","Speed: 5.0ms preprocess, 14.9ms inference, 5.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 14.9ms\n","Speed: 4.7ms preprocess, 14.9ms inference, 5.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 14.8ms\n","Speed: 4.4ms preprocess, 14.8ms inference, 5.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 14.8ms\n","Speed: 4.7ms preprocess, 14.8ms inference, 5.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 18.2ms\n","Speed: 6.0ms preprocess, 18.2ms inference, 6.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 20.2ms\n","Speed: 4.5ms preprocess, 20.2ms inference, 7.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 21.0ms\n","Speed: 10.1ms preprocess, 21.0ms inference, 7.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 20.0ms\n","Speed: 4.9ms preprocess, 20.0ms inference, 7.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 17.7ms\n","Speed: 5.0ms preprocess, 17.7ms inference, 7.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 25.5ms\n","Speed: 6.1ms preprocess, 25.5ms inference, 9.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 17.5ms\n","Speed: 4.7ms preprocess, 17.5ms inference, 7.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 19.1ms\n","Speed: 9.5ms preprocess, 19.1ms inference, 17.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 21.0ms\n","Speed: 7.1ms preprocess, 21.0ms inference, 8.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 20.6ms\n","Speed: 4.9ms preprocess, 20.6ms inference, 9.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 30.0ms\n","Speed: 4.8ms preprocess, 30.0ms inference, 15.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 21.3ms\n","Speed: 5.0ms preprocess, 21.3ms inference, 34.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 36.5ms\n","Speed: 11.8ms preprocess, 36.5ms inference, 8.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 26.0ms\n","Speed: 13.6ms preprocess, 26.0ms inference, 17.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 19.0ms\n","Speed: 7.1ms preprocess, 19.0ms inference, 7.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 22.4ms\n","Speed: 18.9ms preprocess, 22.4ms inference, 7.9ms postprocess per image at shape (1, 3, 576, 1024)\n"]}]},{"cell_type":"markdown","source":["# **Vision Eye**"],"metadata":{"id":"xow70tLMkd8e"}},{"cell_type":"code","source":["from collections import defaultdict\n","import cv2\n","import numpy as np\n","import math\n","from ultralytics import YOLO\n","from ultralytics.utils.plotting import Annotator\n","\n","# Load the YOLOv8 model\n","model = YOLO('content/runs/segment/train/weights/best.pt')\n","\n","# Open the video file\n","video_path = \"/ef3293eb-7311-4fa5-ab53-f4a02a50a737.mp4\"\n","cap = cv2.VideoCapture(video_path)\n","\n","# Store the track history\n","track_history = defaultdict(lambda: [])\n","\n","# Get video properties\n","w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","fps = int(cap.get(cv2.CAP_PROP_FPS))\n","\n","# Define the output video file path with .mp4 extension\n","output_video_path = 'FinalVisionEyetestoutput_video.mp4'\n","\n","# Define the codec and create a VideoWriter object for MP4\n","fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Use the MP4 codec\n","out = cv2.VideoWriter(output_video_path, fourcc, fps, (w, h))\n","\n","# Initialize variables for object counting and speed estimation\n","last_frame_ids = set()\n","\n","# Assuming fps is the frame rate of the video\n","time_interval = 1 / fps  # Time interval between consecutive frames in seconds\n","\n","# Center point for VisionEye distance calculation\n","center_point = (w // 2, h)\n","pixel_per_meter = 100\n","\n","# Initialize variables for object counting and speed estimation\n","last_frame_ids = set()\n","last_frame_times = defaultdict(lambda: 0)  # Initialize last frame times for each track ID\n","\n","# Font parameters\n","font_scale = 0.9  # Reduced font size\n","font_thickness = 5\n","\n","# Loop through the video frames\n","while cap.isOpened():\n","    # Read a frame from the video\n","    success, frame = cap.read()\n","\n","    if success:\n","        # Get current time\n","        current_time = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0\n","\n","        # Run YOLOv8 tracking on the frame, persisting tracks between frames\n","        results = model.track(frame, persist=True, tracker=\"bytetrack.yaml\")\n","\n","        # Get the boxes and track IDs\n","        boxes = results[0].boxes.xywh.cpu()\n","        track_ids = results[0].boxes.id.int().cpu().tolist()\n","\n","        # Visualize the results on the frame\n","        annotated_frame = results[0].plot()\n","\n","        # Plot the tracks and calculate distances\n","        for box, track_id in zip(boxes, track_ids):\n","            x, y, w, h = box\n","            track = track_history[track_id]\n","            track.append((float(x), float(y)))  # x, y center point\n","            if len(track) > 1:  # Calculate distance and speed when there are at least two points\n","                # Calculate distance from center point\n","                distance = math.sqrt((x - center_point[0]) ** 2 + (y - center_point[1]) ** 2) / pixel_per_meter\n","\n","                # Display distance information\n","                cv2.putText(annotated_frame, f'Distance: {distance:.2f} m', (int(x), int(y) - 20),\n","                            cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 255, 255), font_thickness)\n","\n","                # Calculate time interval since last frame\n","                last_frame_time = last_frame_times[track_id]\n","                time_interval = current_time - last_frame_time\n","\n","                # Estimate speed in m/s\n","                if time_interval != 0:  # Avoid division by zero\n","                    speed_m_per_s = distance / time_interval\n","\n","                    # Convert speed from m/s to km/h\n","                    speed_km_per_h = speed_m_per_s * 5/18\n","\n","                    # Display speed information\n","                    cv2.putText(annotated_frame, f'Speed: {speed_km_per_h:.2f} km/h', (int(x), int(y) + 20),\n","                                cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 0, 0), font_thickness)\n","\n","            # Update last frame time for this track\n","            last_frame_times[track_id] = current_time\n","\n","            # Draw the tracking lines\n","            points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))\n","            cv2.polylines(annotated_frame, [points], isClosed=False, color=(211, 211, 211), thickness=2)\n","\n","        # Display count on the annotated frame\n","        object_count = len(boxes)\n","        cv2.putText(annotated_frame, f'Count: {object_count}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 0, 255), font_thickness)\n","\n","        # Write the annotated frame to the output video\n","        out.write(annotated_frame)\n","\n","    else:\n","        # Break the loop if the end of the video is reached\n","        break\n","\n","# Release the video capture object and close the output video\n","cap.release()\n","out.release()\n","cv2.destroyAllWindows()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"d9-fqhBkkkvE","executionInfo":{"status":"error","timestamp":1710606213941,"user_tz":-180,"elapsed":23327,"user":{"displayName":"Elvis kiilu","userId":"18175971843584468454"}},"outputId":"677c509d-0c15-4f66-939a-201233fee72f"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","0: 576x1024 9 cars, 1 minivan, 2 motorcyclists, 30.2ms\n","Speed: 13.5ms preprocess, 30.2ms inference, 14.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 1 minivan, 28.6ms\n","Speed: 6.1ms preprocess, 28.6ms inference, 15.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 2 cars, 1 minivan, 24.2ms\n","Speed: 10.4ms preprocess, 24.2ms inference, 10.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 3 cars, 1 minivan, 24.1ms\n","Speed: 5.6ms preprocess, 24.1ms inference, 13.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 3 cars, 1 minivan, 24.1ms\n","Speed: 6.2ms preprocess, 24.1ms inference, 11.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 3 cars, 1 minivan, 24.1ms\n","Speed: 6.1ms preprocess, 24.1ms inference, 13.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 3 cars, 1 minivan, 24.2ms\n","Speed: 6.3ms preprocess, 24.2ms inference, 15.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 1 car, 1 minivan, 24.1ms\n","Speed: 6.2ms preprocess, 24.1ms inference, 13.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 1 lorry, 1 minivan, 23.5ms\n","Speed: 6.2ms preprocess, 23.5ms inference, 13.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 1 lorry, 1 minivan, 23.0ms\n","Speed: 6.4ms preprocess, 23.0ms inference, 13.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 1 lorry, 1 minivan, 23.0ms\n","Speed: 5.3ms preprocess, 23.0ms inference, 11.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 1 car, 1 lorry, 1 minivan, 19.8ms\n","Speed: 6.2ms preprocess, 19.8ms inference, 12.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 1 minivan, 19.8ms\n","Speed: 5.2ms preprocess, 19.8ms inference, 11.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 1 car, 1 minivan, 19.8ms\n","Speed: 6.5ms preprocess, 19.8ms inference, 11.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 1 minivan, 19.8ms\n","Speed: 5.7ms preprocess, 19.8ms inference, 13.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 1 bus, 4 cars, 19.8ms\n","Speed: 5.7ms preprocess, 19.8ms inference, 13.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 1 bus, 7 cars, 19.8ms\n","Speed: 6.2ms preprocess, 19.8ms inference, 16.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 1 bus, 4 cars, 19.8ms\n","Speed: 6.0ms preprocess, 19.8ms inference, 14.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 1 bus, 7 cars, 19.4ms\n","Speed: 5.9ms preprocess, 19.4ms inference, 15.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 1 bus, 6 cars, 1 lorry, 19.4ms\n","Speed: 6.0ms preprocess, 19.4ms inference, 13.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 1 bus, 6 cars, 19.4ms\n","Speed: 6.8ms preprocess, 19.4ms inference, 14.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 1 bus, 7 cars, 21.6ms\n","Speed: 5.7ms preprocess, 21.6ms inference, 14.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 19.4ms\n","Speed: 5.8ms preprocess, 19.4ms inference, 15.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 19.4ms\n","Speed: 6.1ms preprocess, 19.4ms inference, 16.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 19.4ms\n","Speed: 6.4ms preprocess, 19.4ms inference, 15.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 19.4ms\n","Speed: 6.3ms preprocess, 19.4ms inference, 16.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 19.4ms\n","Speed: 6.5ms preprocess, 19.4ms inference, 17.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 3 cars, 19.3ms\n","Speed: 5.8ms preprocess, 19.3ms inference, 14.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 19.3ms\n","Speed: 6.0ms preprocess, 19.3ms inference, 16.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 19.4ms\n","Speed: 6.5ms preprocess, 19.4ms inference, 16.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 19.4ms\n","Speed: 6.7ms preprocess, 19.4ms inference, 17.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 19.4ms\n","Speed: 6.8ms preprocess, 19.4ms inference, 18.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 3 cars, 1 motorcyclist, 19.3ms\n","Speed: 5.5ms preprocess, 19.3ms inference, 14.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 3 cars, 1 motorcyclist, 19.3ms\n","Speed: 5.6ms preprocess, 19.3ms inference, 12.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 3 cars, 19.1ms\n","Speed: 6.3ms preprocess, 19.1ms inference, 14.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 19.0ms\n","Speed: 6.1ms preprocess, 19.0ms inference, 14.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 1 motorcyclist, 18.9ms\n","Speed: 5.7ms preprocess, 18.9ms inference, 13.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 1 motorcyclist, 18.8ms\n","Speed: 5.9ms preprocess, 18.8ms inference, 14.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 2 cars, 18.8ms\n","Speed: 6.3ms preprocess, 18.8ms inference, 11.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 18.8ms\n","Speed: 6.2ms preprocess, 18.8ms inference, 13.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 18.8ms\n","Speed: 5.9ms preprocess, 18.8ms inference, 15.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 18.8ms\n","Speed: 6.0ms preprocess, 18.8ms inference, 14.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 18.6ms\n","Speed: 6.2ms preprocess, 18.6ms inference, 12.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 18.3ms\n","Speed: 6.1ms preprocess, 18.3ms inference, 12.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 18.3ms\n","Speed: 6.3ms preprocess, 18.3ms inference, 13.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 18.3ms\n","Speed: 5.9ms preprocess, 18.3ms inference, 14.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 1 motorcyclist, 18.3ms\n","Speed: 5.6ms preprocess, 18.3ms inference, 14.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 1 lorry, 1 motorcyclist, 18.3ms\n","Speed: 6.6ms preprocess, 18.3ms inference, 20.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 18.3ms\n","Speed: 6.4ms preprocess, 18.3ms inference, 17.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 1 lorry, 18.3ms\n","Speed: 6.7ms preprocess, 18.3ms inference, 17.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 3 cars, 1 lorry, 18.3ms\n","Speed: 6.5ms preprocess, 18.3ms inference, 15.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 1 lorry, 17.6ms\n","Speed: 6.5ms preprocess, 17.6ms inference, 15.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 3 cars, 1 lorry, 17.4ms\n","Speed: 6.0ms preprocess, 17.4ms inference, 13.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 3 cars, 2 lorrys, 17.4ms\n","Speed: 6.6ms preprocess, 17.4ms inference, 13.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 2 lorrys, 17.1ms\n","Speed: 6.2ms preprocess, 17.1ms inference, 11.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 2 lorrys, 17.1ms\n","Speed: 6.4ms preprocess, 17.1ms inference, 14.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 17.1ms\n","Speed: 6.4ms preprocess, 17.1ms inference, 14.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 17.1ms\n","Speed: 6.3ms preprocess, 17.1ms inference, 15.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 17.1ms\n","Speed: 7.0ms preprocess, 17.1ms inference, 14.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 3 cars, 17.1ms\n","Speed: 6.2ms preprocess, 17.1ms inference, 16.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 3 cars, 17.1ms\n","Speed: 5.8ms preprocess, 17.1ms inference, 15.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 3 cars, 1 motorcyclist, 17.1ms\n","Speed: 6.0ms preprocess, 17.1ms inference, 14.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 1 car, 16.9ms\n","Speed: 6.5ms preprocess, 16.9ms inference, 13.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 1 car, 1 motorcyclist, 16.9ms\n","Speed: 7.1ms preprocess, 16.9ms inference, 15.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 3 cars, 16.8ms\n","Speed: 6.6ms preprocess, 16.8ms inference, 15.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 3 cars, 1 motorcyclist, 16.8ms\n","Speed: 6.0ms preprocess, 16.8ms inference, 12.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 3 cars, 16.8ms\n","Speed: 6.1ms preprocess, 16.8ms inference, 11.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 1 motorcyclist, 16.8ms\n","Speed: 6.5ms preprocess, 16.8ms inference, 10.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 16.8ms\n","Speed: 6.3ms preprocess, 16.8ms inference, 11.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 16.8ms\n","Speed: 6.4ms preprocess, 16.8ms inference, 12.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 1 bus, 5 cars, 16.8ms\n","Speed: 6.0ms preprocess, 16.8ms inference, 11.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 2 cars, 16.7ms\n","Speed: 6.7ms preprocess, 16.7ms inference, 11.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 2 cars, 16.8ms\n","Speed: 5.4ms preprocess, 16.8ms inference, 11.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 3 cars, 16.8ms\n","Speed: 5.8ms preprocess, 16.8ms inference, 13.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 3 cars, 1 lorry, 16.5ms\n","Speed: 5.8ms preprocess, 16.5ms inference, 12.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 2 cars, 1 lorry, 16.5ms\n","Speed: 6.2ms preprocess, 16.5ms inference, 10.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 1 lorry, 16.4ms\n","Speed: 6.1ms preprocess, 16.4ms inference, 14.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 2 cars, 1 lorry, 16.6ms\n","Speed: 6.4ms preprocess, 16.6ms inference, 13.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 16.5ms\n","Speed: 5.3ms preprocess, 16.5ms inference, 14.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 2 cars, 19.6ms\n","Speed: 6.0ms preprocess, 19.6ms inference, 16.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 3 cars, 17.7ms\n","Speed: 6.4ms preprocess, 17.7ms inference, 14.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 2 cars, 16.5ms\n","Speed: 6.1ms preprocess, 16.5ms inference, 19.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 1 car, 16.6ms\n","Speed: 5.9ms preprocess, 16.6ms inference, 16.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 3 cars, 1 motorcyclist, 16.6ms\n","Speed: 5.7ms preprocess, 16.6ms inference, 16.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 3 cars, 16.5ms\n","Speed: 6.0ms preprocess, 16.5ms inference, 13.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 16.5ms\n","Speed: 5.9ms preprocess, 16.5ms inference, 15.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 1 motorcyclist, 16.7ms\n","Speed: 6.0ms preprocess, 16.7ms inference, 15.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 1 car, 16.6ms\n","Speed: 5.8ms preprocess, 16.6ms inference, 13.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 16.5ms\n","Speed: 5.7ms preprocess, 16.5ms inference, 15.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 1 motorcyclist, 16.5ms\n","Speed: 5.8ms preprocess, 16.5ms inference, 11.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 16.5ms\n","Speed: 5.7ms preprocess, 16.5ms inference, 11.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 18.5ms\n","Speed: 6.2ms preprocess, 18.5ms inference, 11.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 19.3ms\n","Speed: 8.4ms preprocess, 19.3ms inference, 13.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 22.9ms\n","Speed: 9.5ms preprocess, 22.9ms inference, 14.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 19.4ms\n","Speed: 5.8ms preprocess, 19.4ms inference, 16.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 19.4ms\n","Speed: 8.9ms preprocess, 19.4ms inference, 14.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 21.1ms\n","Speed: 6.4ms preprocess, 21.1ms inference, 13.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 2 cars, 22.3ms\n","Speed: 6.6ms preprocess, 22.3ms inference, 14.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 22.3ms\n","Speed: 6.5ms preprocess, 22.3ms inference, 14.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 20.6ms\n","Speed: 6.2ms preprocess, 20.6ms inference, 14.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 20.5ms\n","Speed: 5.9ms preprocess, 20.5ms inference, 14.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 1 minivan, 20.6ms\n","Speed: 6.1ms preprocess, 20.6ms inference, 16.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 1 car, 20.1ms\n","Speed: 9.9ms preprocess, 20.1ms inference, 17.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 19.3ms\n","Speed: 5.5ms preprocess, 19.3ms inference, 12.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 19.1ms\n","Speed: 6.0ms preprocess, 19.1ms inference, 12.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 18.9ms\n","Speed: 5.4ms preprocess, 18.9ms inference, 11.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 18.9ms\n","Speed: 5.8ms preprocess, 18.9ms inference, 15.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 19.0ms\n","Speed: 6.2ms preprocess, 19.0ms inference, 14.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 18.9ms\n","Speed: 6.1ms preprocess, 18.9ms inference, 12.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 2 cars, 19.0ms\n","Speed: 6.7ms preprocess, 19.0ms inference, 13.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 19.0ms\n","Speed: 6.1ms preprocess, 19.0ms inference, 12.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 18.9ms\n","Speed: 5.7ms preprocess, 18.9ms inference, 14.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 20.0ms\n","Speed: 5.8ms preprocess, 20.0ms inference, 13.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 18.9ms\n","Speed: 5.8ms preprocess, 18.9ms inference, 15.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 18.9ms\n","Speed: 5.4ms preprocess, 18.9ms inference, 12.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 19.0ms\n","Speed: 6.4ms preprocess, 19.0ms inference, 16.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 18.9ms\n","Speed: 6.2ms preprocess, 18.9ms inference, 15.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 19.0ms\n","Speed: 7.5ms preprocess, 19.0ms inference, 18.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 1 motorcyclist, 18.9ms\n","Speed: 7.0ms preprocess, 18.9ms inference, 18.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 1 minivan, 1 motorcyclist, 19.0ms\n","Speed: 5.5ms preprocess, 19.0ms inference, 18.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 1 bus, 8 cars, 18.9ms\n","Speed: 6.8ms preprocess, 18.9ms inference, 16.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 10 cars, 1 lorry, 1 motorcyclist, 19.3ms\n","Speed: 5.9ms preprocess, 19.3ms inference, 14.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 1 bus, 7 cars, 19.4ms\n","Speed: 5.6ms preprocess, 19.4ms inference, 15.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 1 lorry, 1 motorcyclist, 19.3ms\n","Speed: 5.8ms preprocess, 19.3ms inference, 16.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 1 minivan, 19.4ms\n","Speed: 6.0ms preprocess, 19.4ms inference, 18.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 1 minivan, 19.4ms\n","Speed: 5.9ms preprocess, 19.4ms inference, 21.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 1 minivan, 19.6ms\n","Speed: 6.9ms preprocess, 19.6ms inference, 15.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 1 motorcyclist, 19.6ms\n","Speed: 9.5ms preprocess, 19.6ms inference, 16.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 19.6ms\n","Speed: 7.0ms preprocess, 19.6ms inference, 16.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 19.6ms\n","Speed: 5.5ms preprocess, 19.6ms inference, 16.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 19.6ms\n","Speed: 5.5ms preprocess, 19.6ms inference, 17.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 1 motorcyclist, 19.5ms\n","Speed: 6.6ms preprocess, 19.5ms inference, 15.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 1 motorcyclist, 19.2ms\n","Speed: 6.2ms preprocess, 19.2ms inference, 16.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 19.1ms\n","Speed: 6.0ms preprocess, 19.1ms inference, 19.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 1 minivan, 2 motorcyclists, 18.8ms\n","Speed: 6.2ms preprocess, 18.8ms inference, 17.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 1 minivan, 18.5ms\n","Speed: 6.5ms preprocess, 18.5ms inference, 14.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 20.0ms\n","Speed: 5.7ms preprocess, 20.0ms inference, 17.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 2 cars, 18.6ms\n","Speed: 5.6ms preprocess, 18.6ms inference, 18.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 18.6ms\n","Speed: 6.7ms preprocess, 18.6ms inference, 16.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 18.6ms\n","Speed: 6.7ms preprocess, 18.6ms inference, 17.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 1 motorcyclist, 18.5ms\n","Speed: 5.6ms preprocess, 18.5ms inference, 17.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 18.6ms\n","Speed: 5.8ms preprocess, 18.6ms inference, 17.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 2 cars, 18.6ms\n","Speed: 5.5ms preprocess, 18.6ms inference, 18.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 1 lorry, 1 motorcyclist, 18.6ms\n","Speed: 5.5ms preprocess, 18.6ms inference, 21.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 18.6ms\n","Speed: 7.0ms preprocess, 18.6ms inference, 18.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 1 lorry, 18.7ms\n","Speed: 6.7ms preprocess, 18.7ms inference, 17.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 1 motorcyclist, 18.6ms\n","Speed: 6.0ms preprocess, 18.6ms inference, 16.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 18.6ms\n","Speed: 6.7ms preprocess, 18.6ms inference, 22.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 18.6ms\n","Speed: 6.0ms preprocess, 18.6ms inference, 17.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 1 motorcyclist, 18.6ms\n","Speed: 6.0ms preprocess, 18.6ms inference, 15.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 2 motorcyclists, 18.6ms\n","Speed: 6.6ms preprocess, 18.6ms inference, 15.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 1 motorcyclist, 18.6ms\n","Speed: 7.5ms preprocess, 18.6ms inference, 15.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 18.7ms\n","Speed: 6.8ms preprocess, 18.7ms inference, 18.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 18.5ms\n","Speed: 6.4ms preprocess, 18.5ms inference, 15.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 18.2ms\n","Speed: 6.8ms preprocess, 18.2ms inference, 18.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 17.1ms\n","Speed: 5.8ms preprocess, 17.1ms inference, 16.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 16.9ms\n","Speed: 6.4ms preprocess, 16.9ms inference, 17.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 16.9ms\n","Speed: 6.4ms preprocess, 16.9ms inference, 14.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 3 cars, 1 motorcyclist, 16.9ms\n","Speed: 6.2ms preprocess, 16.9ms inference, 16.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 17.3ms\n","Speed: 6.8ms preprocess, 17.3ms inference, 17.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 16.9ms\n","Speed: 7.5ms preprocess, 16.9ms inference, 15.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 1 motorcyclist, 16.9ms\n","Speed: 6.4ms preprocess, 16.9ms inference, 17.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 16.9ms\n","Speed: 5.9ms preprocess, 16.9ms inference, 15.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 17.0ms\n","Speed: 6.7ms preprocess, 17.0ms inference, 18.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 16.6ms\n","Speed: 6.5ms preprocess, 16.6ms inference, 18.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 10 cars, 1 motorcyclist, 16.4ms\n","Speed: 6.6ms preprocess, 16.4ms inference, 17.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 9 cars, 1 minivan, 15.6ms\n","Speed: 5.7ms preprocess, 15.6ms inference, 17.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 15.5ms\n","Speed: 6.2ms preprocess, 15.5ms inference, 17.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 15.5ms\n","Speed: 6.4ms preprocess, 15.5ms inference, 17.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 1 lorry, 15.5ms\n","Speed: 7.0ms preprocess, 15.5ms inference, 21.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 10 cars, 15.5ms\n","Speed: 6.0ms preprocess, 15.5ms inference, 17.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 9 cars, 1 motorcyclist, 15.5ms\n","Speed: 6.3ms preprocess, 15.5ms inference, 19.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 15.5ms\n","Speed: 6.2ms preprocess, 15.5ms inference, 15.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 11 cars, 15.5ms\n","Speed: 6.1ms preprocess, 15.5ms inference, 16.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 15.5ms\n","Speed: 6.1ms preprocess, 15.5ms inference, 15.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 17.1ms\n","Speed: 6.7ms preprocess, 17.1ms inference, 14.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 10 cars, 15.5ms\n","Speed: 5.9ms preprocess, 15.5ms inference, 13.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 15.5ms\n","Speed: 6.5ms preprocess, 15.5ms inference, 11.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 15.5ms\n","Speed: 6.2ms preprocess, 15.5ms inference, 13.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 15.5ms\n","Speed: 5.9ms preprocess, 15.5ms inference, 11.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 15.5ms\n","Speed: 5.9ms preprocess, 15.5ms inference, 13.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 15.5ms\n","Speed: 6.5ms preprocess, 15.5ms inference, 13.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 15.5ms\n","Speed: 6.6ms preprocess, 15.5ms inference, 13.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 15.5ms\n","Speed: 6.7ms preprocess, 15.5ms inference, 16.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 15.5ms\n","Speed: 5.5ms preprocess, 15.5ms inference, 15.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 16.8ms\n","Speed: 5.7ms preprocess, 16.8ms inference, 17.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 16.7ms\n","Speed: 6.4ms preprocess, 16.7ms inference, 15.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 3 cars, 16.7ms\n","Speed: 6.1ms preprocess, 16.7ms inference, 14.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 16.7ms\n","Speed: 6.3ms preprocess, 16.7ms inference, 15.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 1 motorcyclist, 16.6ms\n","Speed: 5.8ms preprocess, 16.6ms inference, 14.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 1 motorcyclist, 18.9ms\n","Speed: 6.4ms preprocess, 18.9ms inference, 14.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 16.3ms\n","Speed: 6.6ms preprocess, 16.3ms inference, 15.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 16.3ms\n","Speed: 6.8ms preprocess, 16.3ms inference, 13.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 16.4ms\n","Speed: 5.7ms preprocess, 16.4ms inference, 13.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 16.3ms\n","Speed: 6.0ms preprocess, 16.3ms inference, 15.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 16.3ms\n","Speed: 6.2ms preprocess, 16.3ms inference, 14.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 16.3ms\n","Speed: 5.9ms preprocess, 16.3ms inference, 13.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 16.3ms\n","Speed: 6.4ms preprocess, 16.3ms inference, 12.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 9 cars, 16.3ms\n","Speed: 6.6ms preprocess, 16.3ms inference, 11.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 9 cars, 16.3ms\n","Speed: 6.4ms preprocess, 16.3ms inference, 9.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 16.3ms\n","Speed: 7.2ms preprocess, 16.3ms inference, 10.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 16.3ms\n","Speed: 6.3ms preprocess, 16.3ms inference, 14.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 1 minivan, 16.3ms\n","Speed: 6.3ms preprocess, 16.3ms inference, 13.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 16.3ms\n","Speed: 7.1ms preprocess, 16.3ms inference, 12.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 16.3ms\n","Speed: 6.7ms preprocess, 16.3ms inference, 9.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 8 cars, 2 motorcyclists, 16.3ms\n","Speed: 6.5ms preprocess, 16.3ms inference, 10.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 16.3ms\n","Speed: 5.8ms preprocess, 16.3ms inference, 12.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 2 cars, 24.8ms\n","Speed: 7.4ms preprocess, 24.8ms inference, 12.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 3 cars, 17.8ms\n","Speed: 9.4ms preprocess, 17.8ms inference, 16.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 20.1ms\n","Speed: 9.5ms preprocess, 20.1ms inference, 13.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 1 lorry, 19.3ms\n","Speed: 6.5ms preprocess, 19.3ms inference, 11.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 1 lorry, 19.9ms\n","Speed: 6.2ms preprocess, 19.9ms inference, 12.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 1 car, 1 lorry, 21.9ms\n","Speed: 6.7ms preprocess, 21.9ms inference, 17.3ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 1 lorry, 1 minivan, 20.6ms\n","Speed: 9.9ms preprocess, 20.6ms inference, 15.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 3 cars, 1 lorry, 18.9ms\n","Speed: 11.6ms preprocess, 18.9ms inference, 12.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 1 lorry, 21.5ms\n","Speed: 6.1ms preprocess, 21.5ms inference, 16.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 1 lorry, 22.5ms\n","Speed: 6.9ms preprocess, 22.5ms inference, 15.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 2 cars, 21.9ms\n","Speed: 6.9ms preprocess, 21.9ms inference, 15.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 3 cars, 19.3ms\n","Speed: 6.4ms preprocess, 19.3ms inference, 17.1ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 21.9ms\n","Speed: 8.7ms preprocess, 21.9ms inference, 17.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 23.6ms\n","Speed: 8.4ms preprocess, 23.6ms inference, 18.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 20.7ms\n","Speed: 6.2ms preprocess, 20.7ms inference, 17.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 20.3ms\n","Speed: 7.2ms preprocess, 20.3ms inference, 19.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 21.5ms\n","Speed: 6.6ms preprocess, 21.5ms inference, 19.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 9 cars, 1 motorcyclist, 23.8ms\n","Speed: 7.1ms preprocess, 23.8ms inference, 17.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 9 cars, 1 motorcyclist, 20.6ms\n","Speed: 6.0ms preprocess, 20.6ms inference, 15.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 9 cars, 20.6ms\n","Speed: 6.2ms preprocess, 20.6ms inference, 16.4ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 5 cars, 1 motorcyclist, 20.6ms\n","Speed: 6.4ms preprocess, 20.6ms inference, 15.2ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 1 lorry, 1 motorcyclist, 20.7ms\n","Speed: 6.6ms preprocess, 20.7ms inference, 15.6ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 7 cars, 20.0ms\n","Speed: 7.5ms preprocess, 20.0ms inference, 14.9ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 1 motorcyclist, 20.1ms\n","Speed: 7.5ms preprocess, 20.1ms inference, 19.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 6 cars, 20.0ms\n","Speed: 7.7ms preprocess, 20.0ms inference, 18.0ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 20.1ms\n","Speed: 7.8ms preprocess, 20.1ms inference, 15.8ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 20.1ms\n","Speed: 6.8ms preprocess, 20.1ms inference, 13.7ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 3 cars, 20.0ms\n","Speed: 5.9ms preprocess, 20.0ms inference, 13.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 4 cars, 20.0ms\n","Speed: 5.9ms preprocess, 20.0ms inference, 12.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 3 cars, 20.1ms\n","Speed: 6.4ms preprocess, 20.1ms inference, 14.5ms postprocess per image at shape (1, 3, 576, 1024)\n","\n","0: 576x1024 16 cars, 5 motorcyclists, 1 pedestrian, 20.0ms\n","Speed: 6.3ms preprocess, 20.0ms inference, 12.2ms postprocess per image at shape (1, 3, 576, 1024)\n"]},{"output_type":"error","ename":"AttributeError","evalue":"'NoneType' object has no attribute 'int'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-47-b1c78044cb20>\u001b[0m in \u001b[0;36m<cell line: 49>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# Get the boxes and track IDs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxywh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mtrack_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# Visualize the results on the frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'int'"]}]},{"cell_type":"code","source":["import platform\n","import sys\n","import flask\n","\n","# Get operating system information\n","os_info = platform.platform()\n","\n","# Get Python version\n","python_version = sys.version\n","\n","# Get Flask version\n","flask_version = flask.__version__\n","\n","# Print the information\n","print(\"Operating System:\", os_info)\n","print(\"Python Version:\", python_version)\n","print(\"Flask Version:\", flask_version)\n"],"metadata":{"id":"_nn-aZs5Qb-M","outputId":"92345841-d223-4eb0-a6b8-1f147a3abec9","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Operating System: Linux-6.1.58+-x86_64-with-glibc2.35\n","Python Version: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n","Flask Version: 2.2.5\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}